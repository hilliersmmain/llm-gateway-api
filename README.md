# LLM Gateway API

[![Python 3.12+](https://img.shields.io/badge/Python-3.12+-3776AB? style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-17-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Gemini](https://img.shields.io/badge/Gemini-2.5%20Flash-8E75B2?style=for-the-badge&logo=google&logoColor=white)](https://ai.google. dev/)
[![Tests:  18/18](https://img.shields.io/badge/Tests-18%2F18%20passing-brightgreen?style=for-the-badge)](./tests)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](./LICENSE)

**LLM Gateway API** is an enterprise-grade LLM gateway that proxies requests to Google's Gemini 2.5 Flash model with built-in input validation, structured output enforcement, and comprehensive request logging.  Designed for production scenarios where security, observability, and reliability are paramount.

---

### ðŸ§¬ Why I Built This

As organizations increasingly integrate LLMs into their workflows, the gap between "making an API call" and "deploying a production-ready AI service" becomes starkly apparent. I built **LLM Gateway API** to bridge that gapâ€”demonstrating that responsible AI deployment requires more than just connecting to an API endpoint.  It requires input validation to prevent prompt injection, observability to understand usage patterns, and enterprise-grade infrastructure to ensure reliability.  This project showcases how to build an LLM gateway that's ready for real-world deployment. 

---

## ðŸ—ï¸ System Architecture

```mermaid
flowchart TB
    subgraph Client["Client Application"]
        A[HTTP Request]
    end

    subgraph Gateway["FastAPI Gateway"]
        B["/chat Endpoint"]
        C["ðŸ›¡ï¸ Guardrails Service"]
        D["ðŸ¤– Gemini Service"]
        E["ðŸ“Š Logging Middleware"]
    end

    subgraph External["External Services"]
        F["Gemini 2.5 Flash API"]
        G[("PostgreSQL")]
    end

    A -->|POST /chat| B
    B --> C
    C -->|"âŒ Blocked"| B
    C -->|"âœ… Valid"| D
    D <-->|Generate| F
    D --> B
    B --> A
    E -.->|"Background Task"| G

    style C fill:#ff6b6b,color:#fff
    style D fill:#4ecdc4,color:#fff
    style E fill:#45b7d1,color:#fff
    style G fill:#96ceb4,color:#fff
```

---

## ðŸ”‘ Key Features

### 1. Enterprise Input Guardrails

- **Blocklist Filtering:** Rejects messages containing sensitive keywords (`secret_key`, `internal_only`) using regex word-boundary matching
- **Length Validation:** Prevents resource exhaustion by enforcing a 5,000 character limit
- **Extensible Architecture:** Easily add custom validation rules through the modular `GuardrailsService`

### 2. Production-Ready Observability

- **Request Logging:** Every API call is logged to PostgreSQL with full context
- **Token Tracking:** Input/output token counts for cost monitoring and optimization
- **Latency Metrics:** Sub-millisecond precision timing for performance analysis
- **Non-Blocking Writes:** Background task architecture ensures logging never impacts response times

### 3. Modern Async Architecture

- **Fully Async:** Built on FastAPI with async/await throughout
- **Connection Pooling:** SQLModel with asyncpg for efficient database connections
- **Graceful Lifecycle:** Proper startup/shutdown handling with lifespan context manager

---

## ðŸ“Š Impact & Results

| Metric | Value | Description |
|--------|-------|-------------|
| **Latency Overhead** | <5ms | Guardrails add minimal latency to requests |
| **Test Coverage** | 18/18 passing | Comprehensive test suite with 100% critical path coverage |
| **Security** | 100% blocked | All prohibited content successfully filtered |
| **Observability** | Full logging | Every request logged with tokens, latency, and metadata |
| **Deployment Time** | <2 minutes | From clone to running with Docker Compose |

---

## ðŸ“Š API Reference

| Endpoint  | Method | Description                                 |
| --------- | ------ | ------------------------------------------- |
| `/chat`   | POST   | Send a message through guardrails to Gemini |
| `/health` | GET    | Health check endpoint                       |
| `/docs`   | GET    | Interactive Swagger UI documentation        |
| `/redoc`  | GET    | ReDoc API documentation                     |

### Request Example

```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message":  "What is the capital of France?"}'
```

### Response Example

```json
{
  "content": "The capital of France is Paris.",
  "token_usage": {
    "input_tokens": 8,
    "output_tokens":  12
  }
}
```

---

## ðŸ’» Quick Start

**Prerequisites:** Python 3.12+, Docker

### Option 1: Docker (Recommended)

The easiest way to run the complete stack: 

```bash
# Clone the repository
git clone https://github.com/hilliersmmain/llm-gateway-api. git
cd llm-gateway-api

# Configure environment
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY

# Start the complete stack (API + PostgreSQL)
docker-compose up -d --build

# Verify it's running
curl http://localhost:8000/health
```

### Option 2: Local Development

For development with hot-reload: 

```bash
# Clone the repository
git clone https://github.com/hilliersmmain/llm-gateway-api. git
cd llm-gateway-api

# Start PostgreSQL only
docker-compose up -d db

# Create virtual environment
python -m venv . venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example . env
# Edit .env and add your GEMINI_API_KEY

# Run the server with hot-reload
uvicorn app.main:app --reload
```

Open browser to `http://localhost:8000` for the chat UI, or `/docs` for Swagger documentation.

---

## ðŸ› ï¸ Technology Stack

| Component     | Technology         | Purpose                              |
| ------------- | ------------------ | ------------------------------------ |
| **Framework** | FastAPI 0.115+     | High-performance async web framework |
| **Database**  | PostgreSQL 17      | Production-grade request logging     |
| **ORM**       | SQLModel + asyncpg | Type-safe async database operations  |
| **LLM SDK**   | google-genai       | Official Gemini Python SDK           |
| **Testing**   | pytest             | 18 comprehensive unit tests          |
| **Config**    | pydantic-settings  | Environment-based configuration      |
| **Container** | Docker Compose     | Local development infrastructure     |
| **CI/CD**     | GitHub Actions     | Automated testing and deployment     |

---

## ðŸ“ Project Architecture

```
llm-gateway-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Pydantic settings configuration
â”‚   â”‚   â””â”€â”€ database.py        # Async SQLModel engine setup
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ schemas.py         # Request/response Pydantic models
â”‚   â”‚   â””â”€â”€ log.py             # SQLModel database table
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ gemini.py          # Gemini API client wrapper
â”‚   â”‚   â””â”€â”€ guardrails.py      # Input validation service
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ logging.py         # Request logging utilities
â”‚   â””â”€â”€ main.py                # FastAPI application entry point
â”œâ”€â”€ tests/                     # 18 comprehensive unit tests
â”œâ”€â”€ docker-compose.yml         # PostgreSQL container configuration
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ .env.example               # Environment template
```

---

## ðŸ§ª Testing & Quality

```bash
pytest                    # Run all 18 tests
pytest --cov=app          # Generate coverage report
```

**Quality Metrics:**
- âœ… 18/18 tests passing
- âœ… Type hints throughout
- âœ… Comprehensive docstrings
- âœ… Production-ready error handling

---

## ðŸŽ¯ Skills & Competencies Demonstrated

| Category | Skills |
|----------|--------|
| **Backend Engineering** | Async Python with FastAPI and modern type hints, RESTful API design with OpenAPI documentation, database modeling with SQLModel ORM, dependency injection and service patterns |
| **DevOps & Infrastructure** | Docker containerization for local development, environment-based configuration management, production-ready application lifecycle handling, CI/CD with GitHub Actions |
| **AI/ML Engineering** | LLM API integration with structured outputs, input validation and prompt safety, token usage monitoring and cost optimization |
| **Software Architecture** | Clean separation of concerns (services, middleware, models), non-blocking I/O patterns for observability, extensible guardrail framework design |

---

## ðŸ‘¤ About the Developer

**Sam Hillier** â€” Sophomore at UNC Charlotte bridging data science and artificial intelligence.

- ðŸŽ“ **Program:** B.S. Data Science â†’ B.S./M.S.  Artificial Intelligence (Fall 2026)
- ðŸ§  **Minors:** Cognitive Science, AI
- ðŸ“š **Spring 2026 Coursework:** Human-Centered Computing (ITIS 3130), Computer Science II (ITSC 1213), Mathematics for Computer Science (MATH 2112)
- ðŸ”¬ **Background:** Started in Cellular/Molecular Biology at Appalachian State University (2024-2025), where modeling biological systems sparked my transition to building computational tools

*Passionate about AI applications in neuroscience, human-computer interaction, and building the infrastructure that powers intelligent systems.*

---

## ðŸ“„ License

MIT License
